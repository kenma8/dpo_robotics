2025-05-23 01:10:49,446 INFO    MainThread:81097 [wandb_setup.py:_flush():70] Current SDK version is 0.19.11
2025-05-23 01:10:49,446 INFO    MainThread:81097 [wandb_setup.py:_flush():70] Configure stats pid to 81097
2025-05-23 01:10:49,446 INFO    MainThread:81097 [wandb_setup.py:_flush():70] Loading settings from /Users/kenma/.config/wandb/settings
2025-05-23 01:10:49,446 INFO    MainThread:81097 [wandb_setup.py:_flush():70] Loading settings from /Users/kenma/Documents/dpo_robotics/wandb/settings
2025-05-23 01:10:49,446 INFO    MainThread:81097 [wandb_setup.py:_flush():70] Loading settings from environment variables
2025-05-23 01:10:49,446 INFO    MainThread:81097 [wandb_init.py:setup_run_log_directory():724] Logging user logs to /Users/kenma/Documents/dpo_robotics/wandb/run-20250523_011049-5n4869sw/logs/debug.log
2025-05-23 01:10:49,446 INFO    MainThread:81097 [wandb_init.py:setup_run_log_directory():725] Logging internal logs to /Users/kenma/Documents/dpo_robotics/wandb/run-20250523_011049-5n4869sw/logs/debug-internal.log
2025-05-23 01:10:49,579 INFO    MainThread:81097 [wandb_init.py:init():852] calling init triggers
2025-05-23 01:10:49,579 INFO    MainThread:81097 [wandb_init.py:init():857] wandb.init called with sweep_config: {}
config: {'_wandb': {'code_path': 'code/src/train_humanoid_ppo.py'}}
2025-05-23 01:10:49,579 INFO    MainThread:81097 [wandb_init.py:init():893] starting backend
2025-05-23 01:10:49,579 INFO    MainThread:81097 [wandb_init.py:init():897] sending inform_init request
2025-05-23 01:10:49,600 INFO    MainThread:81097 [backend.py:_multiprocessing_setup():101] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2025-05-23 01:10:49,600 INFO    MainThread:81097 [wandb_init.py:init():907] backend started and connected
2025-05-23 01:10:49,602 INFO    MainThread:81097 [wandb_init.py:init():1005] updated telemetry
2025-05-23 01:10:49,618 INFO    MainThread:81097 [wandb_init.py:init():1029] communicating run to backend with 90.0 second timeout
2025-05-23 01:10:49,912 INFO    MainThread:81097 [wandb_init.py:init():1104] starting run threads in backend
2025-05-23 01:10:50,015 INFO    MainThread:81097 [wandb_run.py:_console_start():2573] atexit reg
2025-05-23 01:10:50,015 INFO    MainThread:81097 [wandb_run.py:_redirect():2421] redirect: wrap_raw
2025-05-23 01:10:50,015 INFO    MainThread:81097 [wandb_run.py:_redirect():2490] Wrapping output streams.
2025-05-23 01:10:50,015 INFO    MainThread:81097 [wandb_run.py:_redirect():2513] Redirects installed.
2025-05-23 01:10:50,016 INFO    MainThread:81097 [wandb_init.py:init():1150] run started, returning control to user process
2025-05-23 01:10:50,786 INFO    MainThread:81097 [wandb_run.py:_tensorboard_callback():1645] tensorboard callback: ./runs/ppo_humanoid/20250523-011049/PPO_1, True
2025-05-23 01:10:50,787 INFO    MainThread:81097 [wandb_watch.py:_watch():71] Watching
2025-05-23 01:10:50,788 INFO    MainThread:81097 [wandb_run.py:_config_callback():1436] config_cb None None {'algo': 'PPO', 'policy_class': "<class 'stable_baselines3.common.policies.ActorCriticPolicy'>", 'device': 'cpu', 'verbose': 1, 'policy_kwargs': "{'net_arch': [{'pi': [512, 512, 512], 'vf': [512, 512, 512]}]}", 'num_timesteps': 0, '_total_timesteps': 655360, '_num_timesteps_at_start': 0, 'seed': 'None', 'action_noise': 'None', 'start_time': 1747987850782820000, 'learning_rate': 0.0001, 'tensorboard_log': './runs/ppo_humanoid/20250523-011049', '_last_obs': '[[-0.21997403  0.11970995  0.1174597  ...  0.          0.\n   0.        ]\n [-0.742937    1.0675693  -0.755254   ...  0.          0.\n   0.        ]\n [-0.16203335  1.2389859   1.1648624  ...  0.          0.\n   0.        ]\n ...\n [ 0.85205334  0.13908376 -1.078393   ...  0.          0.\n   0.        ]\n [ 0.45613712  1.1690218   1.5239896  ...  0.          0.\n   0.        ]\n [-0.6461397   0.20834254 -0.8937352  ...  0.          0.\n   0.        ]]', '_last_episode_starts': '[ True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True  True  True  True  True\n  True  True  True  True  True  True  True  True]', '_last_original_obs': '[[ 1.39992984e+00  1.00197573e+00  1.53649516e-04 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n [ 1.39668537e+00  1.00788967e+00 -3.92871238e-03 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n [ 1.40028931e+00  1.00895918e+00  5.05316825e-03 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n ...\n [ 1.40658071e+00  1.00209661e+00 -5.44028549e-03 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n [ 1.40412444e+00  1.00852266e+00  6.73308547e-03 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]\n [ 1.39728591e+00  1.00252873e+00 -4.57649681e-03 ...  0.00000000e+00\n   0.00000000e+00  0.00000000e+00]]', '_episode_num': 0, 'use_sde': 'False', 'sde_sample_freq': -1, '_current_progress_remaining': 1.0, '_stats_window_size': 100, 'ep_info_buffer': 'deque([], maxlen=100)', 'ep_success_buffer': 'deque([], maxlen=100)', '_n_updates': 0, '_custom_logger': 'False', 'env': '<stable_baselines3.common.vec_env.vec_normalize.VecNormalize object at 0x17784ca10>', '_vec_normalize_env': '<stable_baselines3.common.vec_env.vec_normalize.VecNormalize object at 0x17784ca10>', 'observation_space': 'Box(-inf, inf, (348,), float64)', 'action_space': 'Box(-0.4, 0.4, (17,), float32)', 'n_envs': 32, 'n_steps': 2048, 'gamma': 0.995, 'gae_lambda': 0.95, 'ent_coef': 0.01, 'vf_coef': 0.5, 'max_grad_norm': 0.5, 'rollout_buffer_class': "<class 'stable_baselines3.common.buffers.RolloutBuffer'>", 'rollout_buffer_kwargs': '{}', 'batch_size': 256, 'n_epochs': 1000, 'clip_range': '<function get_schedule_fn.<locals>.<lambda> at 0x3365f6340>', 'clip_range_vf': 'None', 'normalize_advantage': 'True', 'target_kl': 'None', 'lr_schedule': '<function get_schedule_fn.<locals>.<lambda> at 0x1659f1940>', 'rollout_buffer': '<stable_baselines3.common.buffers.RolloutBuffer object at 0x17fae8150>', 'policy': 'ActorCriticPolicy(\n  (features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (pi_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (vf_features_extractor): FlattenExtractor(\n    (flatten): Flatten(start_dim=1, end_dim=-1)\n  )\n  (mlp_extractor): MlpExtractor(\n    (policy_net): Sequential(\n      (0): Linear(in_features=348, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=512, out_features=512, bias=True)\n      (5): Tanh()\n    )\n    (value_net): Sequential(\n      (0): Linear(in_features=348, out_features=512, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=512, out_features=512, bias=True)\n      (3): Tanh()\n      (4): Linear(in_features=512, out_features=512, bias=True)\n      (5): Tanh()\n    )\n  )\n  (action_net): Linear(in_features=512, out_features=17, bias=True)\n  (value_net): Linear(in_features=512, out_features=1, bias=True)\n)', '_logger': '<stable_baselines3.common.logger.Logger object at 0x326a45f50>'}
